\documentclass[10pt]{article}

\bibliographystyle{plain}

\usepackage{comment}
\usepackage{fullpage}
\usepackage{color}
\usepackage{amsmath}
\usepackage{amsfonts}
%\usepackage{fullpage}
\usepackage{pdflscape}

\newcommand\D{\ensuremath{\mathrm{d}}}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\pagestyle{empty}

\begin{document}
%\begin{landscape}

\title{BAYESBurst?}
\author{Reed Essick\\ressick@mit.edu}
\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{itemize}
	\item{Work out priors on signal carefully. These include 
		\begin{itemize}
			\item{localized in time in wave-frame (transient) : $h_j(t) = \left(\theta(t+\Delta t) - \theta(t-\Delta t)\right) h_j(t)$}
			\item{localized in frequency in wave-frame (band-limitted) : $h_j(f) = \left(\theta(f+\Delta f) - \theta(t-\Delta f)\right) h_j(f)$}
			\item{signals are distributed uniformly in volume, and all observed strain comes from a single event (astrophysically distributed)}
		\end{itemize}
	     }
	\item{Propose implementation
		\begin{itemize}
			\item{position-space $(\theta, \phi)$ or spherical-harmonics $(Y_{lm})$?}
			\item{time-domain $(h_j(t))$ or frequency domain $(h_j(f))$?}
		\end{itemize}
	     }
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\thispagestyle{empty}
\tableofcontents
\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Notation}

Throughout these notes I adopt the following notation. 
\begin{itemize}
	\item{all sky positions will be given in Earth-fixed coordinates $(\theta, \phi)$. These are the standard polar coordinates, with polar angle $\theta$ and azimuthal angle $\phi$.}
	\item{antenna patterns are functions of souce position $\vec{\Omega}\equiv(\theta,\phi) \in \mathbb{R}^2$ as well as frequency. Most analyses treate the antenna patterns as independent of frequency, but we want to wrap the time-shifts caused by different times-of-arival at different points on the Earth into the antenna patterns. In the frequency domain, this is simlpy a shift in phase $e^{-2\pi i f\Delta t}$.}
        \item{we work in the frequency domain because the antenna patterns, including time delays, are trivial in that basis. We avoid shifting data streams by applying phases in the frequency domain.}
	\item{lower case greek indicies will represent interferometers (ifos). eg: $\beta\in\{L, H, V\}$}
	\item{latin indicies will represent polarization states. eg: $j \in \{+,\times\}$}
	\item{upper case greek indicies will represent sky positions. eg: $\Omega = (\theta,\phi)$ or $\Omega = (l,m)$ as appropriate.}
	\item{we adopt the einstein summation notation for repeated indicies unless otherwise noted. If there is any ambiguity, we'll explicitly write the sums with $\Sigma$ notation}
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{preliminaries}

We begin our analysis with several basic assumptions about interferometric gravitational wave detectors. These include characterizing the noise in the instruments and the detectors' sensitivities to different polarizations and source positions.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{uncorrelated gaussian noise}

We assume that the probability for observing a set of complex noise amplitudes in the fourier domain is

\begin{equation}
p(n_\beta(f)) = \frac{1}{N}\mathrm{exp}\left( -\int\mathrm{d}f\, \sum_\beta \frac{n_\beta \cdot n_\beta^\ast}{S_\beta} \right)
\end{equation}

where we define the gaussian noise power spectrum as

\begin{eqnarray}
\left< n_\beta(f) \right> & = & 0 \\
\left< n_\beta(f) n_\alpha^\ast (f^\prime)\right> & = & \frac{1}{2} S_\beta(f) \delta_{\beta\alpha} \delta(f-f^\prime)
\end{eqnarray}

Note that the probability is simply the noise weighted inner product of the noise realization.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{antenna patterns and time delays}

We follow the conventions used in ~\cite{PhysRevD.63.042003} when defining our antenna patterns. Their equation B7 describes the analytic form for the antenna patterns, which are complicated, but they depend on three parameters.\footnote{Antenna patterns can be defined for other polarizations that are not predicted by General Relativity. Our analysis is general enough to encompass these cases, but we only explicitly consider the case of 2 polarizations.}

\begin{eqnarray}
\mathcal{F}_+ = \mathcal{F}_+(\theta,\phi,\psi) \nonumber\\
\mathcal{F}_\times = \mathcal{F}_\times(\theta,\phi,\psi) \nonumber\\
\end{eqnarray}

where $\theta$ and $\phi$ are the normal spherical coordinates in an Earth-fixed frame. $\psi$ is the ``polarization angle'' and is poorly defined for bursts. Physically, it reflects the relative rotation of the coordinate systems in which we define the gravitational wave and the Earth-fixed frame. Therefore, a rotation of $\psi$ simply mixes the different polarization states and does not affect the signal physically. If we have not model for the signal a priori, we can reconstruct our signal in any coordinate system we choose. This means that we can select $\psi$ arbitrarily without affecting our reconstruction.

Furthermore, because detectors are spatially separated and gravitational waves are expected to travel at the speed of light, true signals will arrive in different detectors at different times. If a source comes from the direction $(\theta,\phi)$, we expect

\begin{eqnarray}
\Delta t_{12} \equiv t_{ifo1} - t_{ifo2} & = & \hat{\Omega}\cdot(\vec{r}_{ifo1}-\vec{r}_{ifo2}) \nonumber \\
                                         & = & \sin\theta\cos\phi(x_{ifo1}-x_{ifo2}) + \sin\theta\sin\phi(y_{ifo1}-y_{ifo2}) + \cos\theta(z_{ifo1}-z_{ifo2})
\end{eqnarray}

Therefore, when accounting for the different times of arrival at various detectors, we can either shift the observed data in time or shift the reconstructed signal as needed. We choose the latter, and furthermore we work in the frequency domain to obviate the shifts in time. One can consider this to be reconstructing the signal as it arrives at the Earth's center (geocenter) rather than at any particular detector.

For each detector, we define the \emph{total} antenna pattern to be the combination of these two effects: sensitivity changes based on relative orientations and time of arrival differences based on relative locations. Therefore, throughout this note we refer to the antenna patterns as 

\begin{equation}
F_{\beta i}(\theta,\phi,\psi) = \mathcal{F}_{\beta i}(\theta,\phi,\psi) \cdot e^{-2\pi i f (t_{\beta}(\theta,\phi) - t_{geo})} = \mathcal{F}_{\beta i} \cdot e^{-2\pi i f \Delta t_{\beta\oplus}}
\end{equation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Point sources}\label{section:point sources}

Here we examine a non-parametric bayesian approach to signal reconstruction for \emph{point sources}. Extended sources are considered in Section \ref{section:extended sources}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{maximum likelihood estimators}

We can define the likelihood ratio as

\begin{eqnarray}
\mathcal{L} = \frac{p(d_\beta - F_{\beta j}h_j)}{p(d_\beta)} & = & \mathrm{exp}\left(\int\mathrm{d}f\, \sum_\beta \frac{\left|d_\beta\right|^2 - \left|d_\beta - F_{\beta j}h_j\right|^2}{S_\beta} \right) \\
                                              & = & \mathrm{exp}\left(\int\mathrm{d}f\, \sum_\beta \frac{d_\beta F_{\beta j}^\ast h_j^\ast + d_\beta^\ast F_{\beta j}h_j - h_kF_{\beta k} F_{\beta j}^\ast h_j^\ast}{S_\beta} \right)
\end{eqnarray}

To obtain our maximum likelihood estimator, we vary this functional with respect to $h_j^\ast(f)$, treating $h_j$ and $h_j^\ast$ as independent variables. Euler-Lagrange equations yield

\begin{eqnarray}
\frac{\delta}{\delta h_m^\ast} \log \mathcal{L} & = & \frac{\delta}{\delta h_m^\ast} \int\mathrm{d}f\, \sum_\beta \frac{d_\beta F_{\beta j}^\ast h_j^\ast + d_\beta^\ast F_{\beta j}h_j - F_{\beta k}h_k F_{\beta j}^\ast h_j^\ast}{S_\beta} = 0 \\
\Rightarrow 0 & = & \frac{\mathrm{d}}{\mathrm{d}f}\left(\frac{\partial}{\partial (\mathrm{d}h_m^\ast/\mathrm{d}f)} \sum_\beta \frac{d_\beta F_{\beta j}^\ast h_j^\ast + d_\beta^\ast F_{\beta j}h_j - F_{\beta k}h_k F_{\beta j}^\ast h_j^\ast}{S_\beta} \right) \nonumber \\
              &   &\ \ \  - \frac{\mathrm{d}}{\mathrm{d} h_m^\ast} \left( \sum_\beta \frac{d_\beta F_{\beta j}^\ast h_j^\ast + d_\beta^\ast F_{\beta j}h_j - F_{\beta k}h_k F_{\beta j}^\ast h_j^\ast}{S_\beta} \right) \\
              & = & - \sum_\beta \frac{\left(d_\beta F_{\beta k}^\ast - h_j F_{\beta j} F_{\beta k}^\ast\right)\delta_{km}}{S_\beta} \\
\Rightarrow \sum_\beta \frac{d_\beta F_{\beta k}^\ast}{S_\beta} & = & \sum_\beta \frac{F_{\beta k}^\ast F_{\beta j} h_j}{S_\beta}
\end{eqnarray}

We now make the following definitions of convenience

\begin{eqnarray}
A_{kj} & \equiv & \sum_\beta \frac{F_{\beta k}^\ast F_{\beta j}}{S_\beta} = A_{jk}^\ast \\
B_{j\beta} & \equiv & \frac{F_{\beta j}^\ast}{S_\beta}\ \ \ \ \ (\mathrm{no\ sum\ over}\ \beta)
\end{eqnarray}

where $A_{kj}$ is an $N_{polarizations} \times N_{polarizations}$ matrix and $B_{\beta j}$ is a $N_{ifos} \times N_{polarizations}$ matrix. With this in hand, we can write the Euler-Lagrange equations in the simple form

\begin{eqnarray}
A_{kj}h_j & = & B_{k\beta}d_\beta \\
\Rightarrow \hat{h}_j & = & \left(A^{-1}\right)_{jk}B_{k\beta}d_\beta
\end{eqnarray}

We should note that $A_{kj}$ is singular for at certain sky locations for a single interferometer, but it should never be singular for two (even-slightly) mis-aligned interferometers. Let us now consider the properties of this estimator. If the data contains a true signal $d_\beta = F_{\beta j}h_j + n_\beta$, we have

\begin{eqnarray}
\hat{h}_j & = & \left(A^{-1}\right)_{jk}B_{k\beta}\left(F_{\beta m}h_m + n_\beta \right)\\
          & = & \left(A^{-1}\right)_{jk}\left(B_{k\beta}F_{\beta m}\right)h_m + \left(A^{-1}\right)_{jk}B_{k\beta}n_\beta
\end{eqnarray}

We note that 

\begin{equation}
B_{k\beta}F_{\beta m} = \sum_\beta \frac{F_{\beta k}^\ast}{S_\beta} F_{\beta_m} = A_{km}
\end{equation}

which yields the pleasant simplification

\begin{eqnarray}
\hat{h}_j & = & \left(A^{-1}\right)_{jk}A_{km} h_m + \left(A^{-1}\right)_{jk}B_{k\beta}n_\beta \\
          & = & \delta_{jm}h_m + \left(A^{-1}\right)_{jk}B_{k\beta}n_\beta \\
\Rightarrow h_j - \hat{h}_j \equiv \epsilon_j & = & \left(A^{-1}\right)_{jk}B_{k\beta}n_\beta 
\end{eqnarray}

and we see that the estimator is \emph{unbiased} with gaussian errors around the actual signal.\footnote{The errors in the reconstructed polarization are functions of the noise in each detector, so they must also be gaussian distributed.}
Explicitly, we can compute the expected distributions of the reconstructed errors as

\begin{eqnarray}
\left<\epsilon_j\right> & = & \left< \left(A^{-1}\right)_{jk}B_{k\beta}n_\beta \right> \\
                        & = & \left(A^{-1}\right)_{jk}B_{k\beta} \left< n_\beta \right> \\
                        & = & 0 \\
\left<\epsilon_j^\ast \epsilon_k\right> & = & \left< n_\alpha^\ast B_{n\alpha}^\ast \left(A^{-1}\right)_{jn}^\ast \left(A^{-1}\right)_{km}B_{m\beta}n_\beta \right> \\
                                        & = & B_{n\alpha}^\ast \left(A^{-1}\right)_{jn}^\ast \left(A^{-1}\right)_{km}B_{m\beta} \left< n_\alpha^\ast n_\beta \right> \\
                                        & = & B_{n\alpha}^\ast \left(A^{-1}\right)_{jn}^\ast \left(A^{-1}\right)_{km}B_{m\beta} \left(\frac{1}{2}S_\beta\delta_{\alpha\beta} \right) \\
                                        & = & \frac{1}{2} \left(A^{-1}\right)_{jn}^\ast \left(A^{-1}\right)_{km}  \sum_\beta \left\{B_{n\beta}^\ast B_{m\beta} S_\beta\right\} \\
                                        & = & \frac{1}{2} \left(A^{-1}\right)_{jn}^\ast \left(A^{-1}\right)_{km}  A_{mn} \\
                                        & = & \frac{1}{2} \left(A^{-1}\right)_{jn}^\ast \delta_{kn} \\
                                        & = & \frac{1}{2} \left(A^{-1}\right)_{jk}^\ast
\end{eqnarray}

Note that the standard deviation increases when the antenna patterns are small. This is because the network is less sensitive to the actual strain signal and we should expect larger errors in the reconstruction.

This also means that we can write the likelihood as 

\begin{eqnarray}
\mathcal{L}  & = & \mathrm{exp}\left( \int\mathrm{d}f\, \sum_\beta \frac{\left|d_\beta\right|^2 - \left|d_\beta - F_{\beta j}\left(\hat{h}_j+\epsilon_j\right)\right|^2}{S_\beta} \right) \\
& = & \mathrm{exp}\left( \int\mathrm{d}f\, d_\beta B_{\beta j}\left(\hat{h}_j+\epsilon_j\right)^\ast + d_\beta^\ast B_{\beta j}^\ast\left(\hat{h}_j+\epsilon_j\right) - \left(\hat{h}_j+\epsilon_j\right)^\ast A_{jk} \left(\hat{h}_k+\epsilon_k\right) \right) \\
& = & \mathrm{exp}\left( \int\mathrm{d}f\, 
  d_\beta      B_{\beta j}      \left(A^{-1}\right)_{jk}^\ast B_{k\alpha}^\ast d_\alpha^\ast
+ d_\beta^\ast B_{\beta j}^\ast \left(A^{-1}\right)_{jk}      B_{k\alpha}      d_\alpha  
- d_\beta^\ast B_{m\beta}^\ast\left(A^{-1}\right)_{mj}^\ast A_{jk} \left(A^{-1}\right)_{kn}B_{n\alpha}d_\alpha
\right. \nonumber \\
&  & \left. \ \ \ \ \ \ \ \ \ \ \ 
- \epsilon_j^\ast                                            A_{jk} \epsilon_k
+ d_\beta      B_{\beta j}      \epsilon_j^\ast 
+ d_\beta^\ast B_{\beta j}^\ast \epsilon_j 
- d_\beta^\ast B_{m\beta}^\ast \left(A^{-1}\right)^\ast_{jm} A_{jk} \epsilon_k  
- \epsilon_j^\ast                                            A_{jk} \left(A^{-1}\right)_{kn} B_{n\alpha} d_\alpha 
\right) 
\end{eqnarray}

Exchanging dummy indicies and using the fact that $A_{jk}$ is Hermitian shows that many terms cancel, including all linear terms in $\epsilon_j$, and the final likelihood ratio can be written as

\begin{equation}
\mathcal{L} = \frac{p(d_\beta - F_{\beta j}h_j)}{p(d_\beta)} = \mathrm{exp}\left( \int\mathrm{d}f\, d_\beta^\ast B_{\beta j}^\ast \left(A^{-1}\right)_{jk} B_{k\alpha} d_\alpha - \epsilon_j^\ast A_{jk} \epsilon_k \right)
\end{equation}

which has a pleasing form. We see that the likelihood ratio is gaussian distributed around it's maximum value.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{dominant polarization frame}

As we've written $A_{jk}$, the off-diagnal components will most likely be non-zero. However, we also have freedom to choose the coordinate system in which we reconstruct the signal. This is controlled by the choice of polarization angle ($\psi$) in the definition of the antenna patterns. It can be shown that changing $\psi$ is equivalent to rotating the wave-frame coordinate system and therefore mixing $h_j \rightarrow h_j^\prime = U(1)h_j$. By appropriate choice of $\psi$, we can diagonalize $A_{jk}$. This is appealing for several reasons, not the least of which is lower computational complexity. It also allows us to easily identify some interesting featurs of networks of interferometric gravitational wave-detectors. In general, we can write

\begin{equation}
A_{jk} = s_{j} \delta_{jk}
\end{equation}

where some of the $s_{j}$ may be vanishingly small, but the set satisfies

\begin{equation}
\sum\limits_i s_i = \sum\limits_{i,\beta} \frac{F_{\beta i}^\ast F_{\beta i}}{S_\beta}
\end{equation}

This choice of coordinate system, in which $A_{jk}$ is diagonal, is often called the \emph{dominant polarization frame.} We should also note that this is a feature of the relative orientations of the detectors and not their relative locations. The time of arrival difference cancel out because of the complex conjugation involved in the definition of $A_{jk}$, and therefore this matrix only depends on the detectors' orientations.

\subsubsection{singular $A_{jk}$ and effective number of polarizations}

We note that $s_{j}$ may not be non-zero for all source positions. In fact, for a single detector and two polarizations, it is straightforward to show that

\begin{eqnarray}
s_{0} & = & \frac{\left|F_0(\theta,\phi,\psi=\psi_o)\right|^2 + \left|F_1(\theta,\phi,\psi=\psi_o)\right|^2}{S} \\
s_{1} & = & 0 \\
\end{eqnarray}

where we've explicitly stated the ``original'' antenna patterns in a frame defined by $\psi_o$. Here, we notice that $A_{jk}$ is \emph{singular}. Whenever $A_{jk}$ is singular, it means the detector network is effectively insensitive to one or more polarization channels. Therefore, a single detector is effectively sensitive to only a single polarization channel for all source positions. These eigenvalues may vary over the sky for more complicated detector networks. 

An interesting case is a two-detector network with slightly mis-aligned detectors. In this case, $s_1 \sim |F_{1j}-F_{2j}|^2$ to lowest order in mis-alignment. If the detectors are only slightly mis-aligned, the network's sensitivity to the second polarization is very small but \emph{non vanishing.}

In practice, if $A_{jk}$ is singular for a set of points on the sky, we simply restrict our reconstruction to a subset of polarization channels to which the network is sensitive. This defines the \emph{effective number of polarizations} to which the network is sensitive from any direction in the sky.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{posterior probabilities}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{sky position}

The useful distributions are the posteriors for the signal parameters. In this case, the full posterior can be written as

\begin{equation}
p(h_j, \theta, \phi|d_\beta) = \frac{p(d_\beta|h_j, \theta, \phi)p(h_j, \theta, \phi)}{p(d_\beta)}
\end{equation}

In general, this is a very difficult function to compute. However, if we restrict ourselves to the posterior for the sky position

\begin{equation}
p(\theta, \phi|d_\beta) = \int\mathcal{D}h_j\, \frac{p(d_\beta|h_j, \theta, \phi)p(h_j, \theta, \phi)}{p(d_\beta)}
\end{equation}

where the integral is taken over all possible signals $h_j = \hat{h}_j +\epsilon_j$. This means that, at a given $(\theta, \phi)$, we can exchange the measure for something tractable : $\mathcal{D}h_j = \mathcal{D}\epsilon_j$. Furthermore, each frequency is independent in this integral, so we can exchange the order of the marginalization over $h_j$ and the integration over $f$. This means we can analytically compute the posterior sky map

\begin{eqnarray}
p(\theta, \phi|d_\beta) & = & \int\mathcal{D}\epsilon_j\, \mathrm{exp}\left( \int\mathrm{d}f\, d_\beta^\ast B_{\beta j}^\ast \left(A^{-1}\right)_{jk} B_{k\alpha} d_\alpha - \epsilon_j^\ast A_{jk} \epsilon_k \right) p(h, \theta, \phi) \\
 & = & \prod\limits_{f} \mathrm{exp}\left( d_\beta^\ast B_{\beta j}^\ast \left(A^{-1}\right)_{jk} B_{k\alpha} d_\alpha \right) \int\limits_{-\infty}^{\infty}\mathrm{d}^{N_p} \epsilon_j\, \mathrm{exp}\left(- \epsilon_j^\ast A_{jk} \epsilon_k \right) p(\hat{h}_j + \epsilon_j, \theta, \phi) 
\end{eqnarray}

where $N_p$ is the number of polarization states. The only barrier to evaluating these integrals analytically is the prior $p(h_j, \theta, \phi)$, which we can reasonably assume will take the form

\begin{equation}
p(h_j, \theta, \phi) = p(h_j) p(\theta,\phi) = p(h_j) \frac{1}{4\pi}
\end{equation}

where we've assumed the prior on $(\theta, \phi)$ is uniform across the sky (constant probability per steradian)\footnote{This assumption is easily relaxed and does not affect the marginalization. Any prior is allowed on $(\theta,\phi)$ and it will simply come outside the integral.} Furthermore, we can assume the most uninformative prior on $h_j$, so that

\begin{equation}
p(h_j) = constant
\end{equation}

Under these assumptions\footnote{Other assumptions may render this integral untractable analytically, but we could, for example, choose a gaussian on $h_j$ and still evaluate the integral analytically.}, we have a very simple form for the posterior

\begin{eqnarray}
p(\theta, \phi|d_\beta) & = & \frac{constant}{4\pi}\prod\limits_{f} \mathrm{exp}\left( d_\beta^\ast B_{\beta j}^\ast \left(A^{-1}\right)_{jk} B_{k\alpha} d_\alpha \right) \int\limits_{-\infty}^{\infty}\mathrm{d}^{N_p} \epsilon_j\, \mathrm{exp}\left(- \epsilon_j^\ast A_{jk} \epsilon_k \right) \\
 & = & \frac{constant}{4\pi}\prod\limits_{f} \mathrm{exp}\left( d_\beta^\ast B_{\beta j}^\ast \left(A^{-1}\right)_{jk} B_{k\alpha} d_\alpha \right) \sqrt{(2\pi)^{N_p}\left|\left(A^{-1}\right)_{jk}\right|}
\end{eqnarray}

Importantly, the marginalization preferentially gives more posterior probability to locations with \emph{lower} antenna patterns, and therefore locations that are \emph{less sensitive} to true gravitaitonal wave signals. This is counter intuitive (one expects there to be more posterior where the network is more sensitive), and is an artifact of the assumption $h_j = constant$. If all signals are equally likely, then the marginalization will select those regions with more allowed ``volume'' in the space of possible signals. This corresponds to locations with larger errors in the reconstructed signals, which are locations with \emph{smaller} antenna patterns. However, applying even a somewhat arbitrary prior on $h_j$ that favors smaller signals can fix this problem.

We should note that the only dependence on the data streams $d_\beta$ comes from the maximum likelihood estimate, which is quadratic in the data. Everything else can be computed \emph{exactly once} for all sky positions $(\theta, \phi)$ and then used to filter the data. 

We also note that the antenna patters \emph{naturally} modulate the posterior through the marginalization. This means that when $N_p=N_{ifo}$ (and for any $(\theta, \phi)$ the maximum likelihood estimator exactly reproduces the data streams) and the likelihood ratio is unity for all $(\theta,\phi)$, \emph{the posterior will not be uniform}. This non-uniformity is independent of the data streams and reflects the different sensitivities of the detector network at different points in the sky. Without a prior, this marginalization favors locations with \emph{low} antenna patters and very little sensitivity to actual signals. Adding a realistic prior on $h_j$ should allow us to include effects like triangulation by assigning higher priors to signals with less total energy. However, the prior will contain terms which depend on the data and may complicate the simple form of our current posterior. Furthermor, the exact form for this prior is uncertain. However, to obtain different posteriors for different data streams, we will have to impose some prior when $N_p=N_{ifo}$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{gaussian priors on $h_j$}

A prior on $h_j$ is required to give posteriors that depend on the data in 2-detector networks. Some possible examples are

\begin{equation}
p(h_j) \propto \mathrm{exp}\left( -h_k^\ast Z_{kj} h_j \right)
\end{equation}

where $Z_{jk} = Z_{kj}^\ast$. This has been called a \emph{white-noise prior}. Choice of $Z_{kj}$ is arbitrary. This prior is not particularly well motivated beyond the fact that the marginalization is still tractable. With such a prior, we can write

\begin{eqnarray}
p(\theta, \phi|d_\beta) & \propto & p(\theta,\phi) \int\mathcal{D}h_j\, \mathrm{exp}\left( \int\mathrm{d}f\, \hat{h}_j^\ast A_{jk} \hat{h}_k - \epsilon_j^\ast A_{jk} \epsilon_k - \hat{h}_j^\ast Z_{jk} \hat{h}_k - \hat{h}_j^\ast Z_{jk} \epsilon_k - \epsilon_k^\ast Z_{jk} \hat{h}_k - \epsilon_j^\ast Z_{jk} \epsilon_k \right) \nonumber \\
& = & p(\theta, \phi) \int\mathcal{D}h_j\, \mathrm{exp}\left( \int\mathrm{d}f\, \hat{h}_j^\ast \left(A-Z\right)_{jk} \hat{h}_k - \left[ \epsilon_j^\ast \left(A+Z\right)_{jk}\epsilon_k +\hat{h}_j^\ast Z_{jk} \epsilon_k + \epsilon_k^\ast Z_{jk} \hat{h}_k^\ast \right] \right) \nonumber \\ 
& = & p(\theta, \phi) \int\mathcal{D}h_j\, \mathrm{exp}\left( \int\mathrm{d}f\, \hat{h}_j^\ast \left(A-Z\right)_{jk} \hat{h}_k + \zeta_j^\ast \Phi_{jk} \zeta_k - \left(\zeta_j + \epsilon_j\right)^\ast \Phi_{jk} \left(\zeta_k + \epsilon_k\right) \right)
\end{eqnarray}

where $\zeta_k = \left(\Phi^{-1}\right)_{kj}Z_{jm}\hat{h}_m$ and $\Phi_{jk} = \left(A+Z\right)_{jk}$. WE can shift the marginalization measure to integrate over the gaussian terms independent of $\hat{h}_j$ to obtain

\begin{eqnarray}
p(\theta, \phi| d_\beta) & = & p(\theta,\phi) \prod\limits_f \mathrm{exp}\left( \hat{h}_j^\ast \left(A-Z\right)_{jk} \hat{h}_k + \zeta_j^\ast \Phi_{jk} \zeta_k \right) \sqrt{(2\pi)^{N_p} \left|\Phi^{-1}\right|} \\
& = & p(\theta,\phi) \prod\limits_f \mathrm{exp}\left( \hat{h}_j^\ast \left(A-Z\right)_{jk} \hat{h}_k + \hat{h}_m^\ast Z_{mj} \left(A+Z\right)^{-1}_{jk} Z_{kn} \hat{h}_n \right) \sqrt{(2\pi)^{N_p} \left|\left(A+Z\right)^{-1}_{jk}\right|} \nonumber \\
& = & p(\theta,\phi) \prod\limits_f \mathrm{exp}\left( \hat{h}_j^\ast \left( \left(A-Z\right)_{jk} + Z_{jm} \left(A+Z\right)^{-1}_{mn} Z_{nk} \right) \hat{h}_k \right) \sqrt{(2\pi)^{N_p} \left|\left(A+Z\right)^{-1}_{jk}\right|}
\end{eqnarray}

Similarly, if we assume a gaussian prior on $h_j$ with some non-zero mean $H_j$, so that

\begin{equation}
p(h_j) \propto \mathrm{exp}\left( -(h_k-H_k)^\ast Z_{kj} (h_j-H_j) \right)
\end{equation}

 we obtain the following

\begin{equation}
p(\theta, \phi| d_\beta) = p(\theta,\phi) \prod\limits_f \mathrm{exp}\left( \hat{h}_j^\ast \left(A\right)_{jk} \hat{h}_k - (\hat{h}_j-H_j)^\ast \left(Z_{jk} - Z_{jm} \Phi^{-1}_{mn} Z_{nk} \right) (\hat{h}_k-H_k) \right) \sqrt{(2\pi)^{N_p} \left|\Phi^{-1}\right|}
\end{equation}

When we include the proper normalization for the prior on $h_j$ as well as the \emph{effective number of polarizations} defined by $N^\prime_{p}=\mathrm{rank}\{A\}$, this posterior takes the following form

\begin{equation}
p(\theta,\phi|d_\beta) = p(\theta,\phi) \left(2\pi\right)^{N^\prime_{p}} \prod\limits_f \mathrm{exp} \left( \hat{h}_j^\ast \left(A\right)_{jk} \hat{h}_k - (\hat{h}_j-H_j)^\ast \left(Z_{jk} - Z_{jm} \Phi^{-1}_{mn} Z_{nk} \right) (\hat{h}_k-H_k) + \frac{1}{2}\log\left( \left|\Phi^{-1}\right| \left|Z\right|\right)\right)
\end{equation}

where $A$, $\Phi$, and $Z$ are $N^\prime_{p}\times N^\prime_{p}$ matrices, restricted to the non-singular subspace of $A$. However, this also assumes that $Z=\sigma^{-2}\mathbb{I}_{N^\prime_{p}\times N^\prime_{p}}$. By including the prior's normalizations, marginalization over extra degrees of freedom ($N_{p}>N^\prime_{p}$) contribute a factor of unity.

Furthermore, we may consider linear combinations of gaussians

\begin{equation}
p(h_j) = \sum_{N} C_N \cdot \mathrm{exp}\left( -\left(h_k-H^{(N)}_k\right)^\ast Z_{kj}^{(N)} \left(h_j-H^{(N)}_j\right) \right)
\end{equation}

where $N$ indexes the gaussian. Again, choice of the $Z_{kj}^{(N)}$ are somewhat arbitrary, but each term in this sum can be evaluated through the marginalization. We might be able to decompose more general priors into this form, which will then give us an analytic forumla for the posterior in terms of the decomposition. Explicitly, this is\footnote{With clever algebra, we may be able to cast this into something more recognizable. For instance, the sum of the products should be the product of the sums and we can exchange the order of the $\sum_{N}$ and $\prod_{f}$.}

\begin{eqnarray}
p(\theta, \phi|d_\beta) & = & p(\theta, \phi) \sum\limits_{N} C_N \prod\limits_f \mathrm{exp}\left( \hat{h}_j^\ast \left(A\right)_{jk} \hat{h}_k - \left(\hat{h}_j-H^{(N)}_j\right)^\ast \left(Z^{(N)}_{jk} - Z^{(N)}_{jm} \left(A+Z^{(N)}\right)^{-1}_{mn} Z^{(N)}_{nk} \right) \left(\hat{h}_k-H^{(N)}_k\right) \right) \nonumber \\
                        &   & \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \times\ \sqrt{(2\pi)^{N^\prime_p} \left|\left(A+Z^{(N)}\right)^{-1}_{jk}\right| \left|Z^{(N)}\right|}
\end{eqnarray}

Importantly, if we choose many narrow gaussians we can approximate an arbitrary prior (sum of $\delta$-functions). We can also endow $Z^{(N)}_{jk}$, $H^{(N)}_{j}$ with frequency dependence without any major modifications. This means we can demand that there is equal energy in each frequency bin so that $h\propto1/f$, or something similar, with appropriate definitions for $Z^{(N)}_{jk}$ and/or $H^{(N)}_j$. Note that this looks like the prior with modifications to the coefficients $C_N$ based on the marginalization over $\epsilon_j$. It may not be possible to re-sum these terms analytically to explicitly state the posterior in closed form (assuming we've expanded a closed form prior into gaussians). \emph{Importantly}, this gives us a way to explicitly compute the posterior without sampling the parameters space of possible signals. All computations are done analytically assuming constant $(\theta,\phi)$, which could provide large speed-ups computationally over Monte-Carlo Markov-Chain algorithms.

In fact, a simple error minimization argument allows us to determine the optimal coefficients for an arbitrary set of gaussian priors when they are used to approximate an arbitrary function $f(h)$. If we define each gaussian by it's mean and standard deviation as $\left|\mu_n,\sigma_n\right>$, then we have the overlap matrix

\begin{equation}
M_{nm} = \left<\mu_n,\sigma_n|\mu_m,\sigma_m\right>
\end{equation}

where the inner product is defined as $\left<a|b\right>=\int\limits_{-\infty}^{\infty}\mathrm{d}h\ a\cdot b$.

Minimizing the sum-square error of the approximation yields a set of coefficients

\begin{equation}
C_k = \left(M^{-1}\right)_{km}\left<\mu_m,\sigma_m|f\right>
\end{equation}

We can also derive the optimal placement of a fixed number of gaussians using a similar method. However, the result is not partitularly illuminating and simply selecting a reasonable set of gaussians by hand should suffice.

For the special case of zero-centered gaussians ($\mu_m=0\,\forall\,m$) and $f\propto h^{-4}$, then we have

\begin{eqnarray}
M_{nm} = M_{mn} & = & \sqrt{\frac{2\sigma_n\sigma_m}{\sigma_n^2+\sigma_m^2}} \\
\left<\sigma_m|f\right> & \sim & 2\int\limits_{\epsilon << \sigma_m}^{\infty}\mathrm{d}h\, \left(h/h_o\right)^{-4} \left(\pi \sigma_m^2\right)^{-1/4} \mathrm{exp}\left(-\frac{h^2}{2\sigma_m^2} \right) \\
                        & \sim & 2\int\limits_{\epsilon/\sigma_m << 1}^{\infty}\mathrm{d}x\sigma_m\, \left(x\sigma_m/h_o\right)^{-4} \left(\pi \sigma_m^2\right)^{-1/4} \mathrm{exp}\left(-\frac{x^2}{2} \right) \\
                        & \sim & \sigma_m^{-13/4} \left[ 2 h_o^{4}(\pi)^{-1/4}\int\limits_{\varepsilon << 1}^{\infty}\mathrm{d}x\, x^{-4} \mathrm{exp}\left(-\frac{x^2}{2} \right) \right]\\
C_k & = & \left(M^{-1}\right)_{km} \sigma_m^{-13/4}\cdot constant\\
\end{eqnarray}

While the Grahm-Schmidt decomposition naturally controls the contributions from wide priors (small $Z$), we see that the coefficients blow up for narrow priors (big $Z$). It turns out that in the limit of $A\ll Z$, the algorithm returns nearly uniform posteriors. Because the leading coefficient increases as $Z$ decreases, we obtain very large contributions from large-$Z$ priors (in the sum). These large-$Z$ contributions can overwhelm any meaningful information from smaller $Z$ terms if they are retained. The natural solution is to truncate the prior near the noise floor because we are unlikely to detect anything with strain significantly smaller than the noise floor. Therefore, the Grahm-schmidt amplitude controls the prior at large widths (small $Z$) and we impose a minimum width (small $Z$) near the noise floor by hand. With these two limiting cases in hand, we should be able to approximate almost an arbitrary prior.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{other priors on $h_j$}

Alternatively, we can write down some astrophysically motivated prior, such as uniform in co-moving volume. However, for burst signals, we do not immediately have a good estimate for the distance $D$. We can relate this to the observed data through

\begin{equation}
\frac{E_{GW}}{D_L^2} \propto \int\mathrm{d}f\, f^2 h_j^\ast h_j
\end{equation}

To obtain a prior on $h_j$, we should marginalize over all possible $D_L$ and $E_{GW}$.

\begin{eqnarray}
p(h,E,D)\mathrm{d}h\mathrm{dE}\mathrm{dD} & = & p(h|E,D)\mathrm{d}h \cdot p(E)\mathrm{d}E \cdot p(D)\mathrm{d}D \\
                                          & \propto & \delta\left(h-\sqrt{\frac{E}{D^2}}\right)\mathrm{d}h \cdot \mathrm{d}E \cdot D^2 \mathrm{d}D \\
\end{eqnarray}

where $h^2=\int\mathrm{d}f\, f^2 h_j^\ast h_j$. Marginalization yields

\begin{eqnarray}
p(h) & \propto & \int\mathrm{d}E\int\mathrm{d}D D^2 \delta\left(h-\sqrt{\frac{E}{D^2}}\right) \\
     & \propto & \int\mathrm{d}E\int\mathrm{d}D D^2 \delta\left(D-\sqrt{\frac{E}{h^2}}\right)\frac{\sqrt{E}}{h^2} \\
     & \propto & \int\mathrm{d}E E^{3/2} h^{-4} \\
     & \propto & h^{-4}
\end{eqnarray}

We therefore expect an astrophycially motivated prior on $h_j$ to be something like

\begin{equation}
p(h_j(f)) \propto \left(\int\mathrm{d}f h_j^\ast h_j \right)^-2
\end{equation}

Furthermore, we can approximate this function as a sum of gaussians

\begin{eqnarray}
p(h_j(f)) & \approx & \sum\limits_n C_n \mathrm{exp}\left(-Z_n \int\mathrm{d}f h_j^\ast h_j \right) \\
          & = & \sum\limits_n C_n \mathrm{exp}\left(-\int\mathrm{d}f\, h_j^\ast Z_n\delta_{jk} h_k\right) \\
          & = & \sum\limits_n C_n \prod\limits_f \mathrm{exp}\left(-h_j^\ast(f) Z_n\delta_{jk} h_k(f)\right) \\
\end{eqnarray}

We note that \emph{this is not equivalent to the product of independent priors on each frequency compenent}, because in this case the sum of the product is not the product of the sum. However, this can still be implemented in a straightforward way within our existing framework. If we want to look for wide-band signals, then perhaps we should modify $Z_n\rightarrow f^2 Z_n$, so there is a frequency dependent prior. The argument about the energy scaling with luminosity distance is then exact, regardless of the signal's bandwidth.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{singular $A_{jk}$ and priors on $h_j$}

If $A_{jk}$ is singular, then the network is insensitive to at least one polarization. We can simply restrict ourselves to a subset of polarizations to which the detector network is sensitive if we properly normalize our priors so that

\begin{equation}
\int\mathcal{D}h_j\ p(h_j) = 1
\end{equation}

This means that we can simply neglect the polarizations we cannot detect without worrying about differences in normalizations between different parts of the sky. The marginalization of the polarizations to which the network is insensitive will simply contribute a factor of unity.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{signal morphology}

Alternatively, we can attempt to calculate the posterior for the actual signal $h_j$, which we obtain through marginalization over $(\theta, \phi)$. This means computing the following

\begin{equation}
p(h_j|d_\beta) = \int\mathrm{d}\cos\theta\mathrm{d}\phi\, \frac{p(d_\beta|h_j, \theta, \phi)p(h_j, \theta, \phi)}{p(d_\beta)}
\end{equation}

This is a much more difficult problem, and unfortunately it may not be tractable analytically. However, for each ($\theta,\phi$) we can compute the mean and variance of the gaussian likelihood function. Marginalization can be done numerically by simply summing over pixels. This can be done by recording the mean, covariance matrix, and amplitude of the likelihood associated with each pixel. We can then compute the posterior for many values of $h_j$ by simply computing the gaussians and summing. Arbitrary priors can be applied to $h_j$ in a straightforward manner a postiori. Furthermore, priors on ($\theta,\phi$) can also be incorporated as part of the summation without much computational complexity.

We should be careful that we add likelihoods using the same wave-frame coordinate system for all ($\theta,\phi$). Furthermore, we will reconstruct the distribution over the complex variables $h_j$, when we are most likely interested in $|h_j|$ which may require marginalization over the phase.

With this posterior in hand, we can make definite statements about the p-value associated with an observed strain that is inconsistent with no-signal. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{model selection}

As we have currently formulated our posterior, each frequency bin is independent and we assign two parameters to each frequency bin. This can be detrimental if we include too many frequency bins when modeling our signal, in particular if we include frequency bins where there is no signal and we simply reconstruct noise. These extra, uninformative, parameters add uncertainty through their marginalization but do not add information through the likelihood. If we include too many bins, we can become dominated by the marginalization, which is independent of data.

However, bayesian statistics naturally includes a way to select models based on the evidence. We can implement this through a \emph{Bayes Factor}

\begin{equation}
B \equiv \frac{p(signal+noise|d_\beta)}{p(noise|d_\beta)}\cdot\frac{p(noise)}{p(signal+noise)} = \frac{\int\mathrm{d}\cos\theta\mathrm{d}\phi\mathcal{D}h_j p(d_\beta|\theta,\phi,h_j,signal+noise)p(h_j|signal+noise)}{p(d_\beta|noise)}
\end{equation}

We can compute the bayes factor separately for each frequency bin through straightforward marginalization. The integral over all possible waveforms can be done analytically, but the marginalization over the source position must be done numerically. There are two ways to proceed once we have the bayes factors:

\begin{enumerate}
	\item{Apply a threshold to $B(f)$ and only include frequency bins with $B\geq B_{thr}$ in our reconstruction. This introduces an arbitrary threshold for $B$.}
	\item{Model-average for each frequency bin and compute the total posterior as the product of the posteriors for each bin. This avoids the arbitrary threshold for $B$ but requires knowledge of the prior odds.}
\end{enumerate}

Model-averaging each frequency bin is straightforward. In essence, we weight the posterior for $(\theta,\phi)$ by the posterior for each model.

\begin{eqnarray}
p(\theta,\phi|d_\beta) & = & p(\theta,\phi|d_\beta,signal+noise)p(signal+noise|d_\beta) + p(\theta,\phi|d_\beta,noise)p(noise|d_\beta) \\
                       & = & p(noise|d_\beta)\left(p(\theta,\phi|d_\beta,signal+noise)\cdot B\frac{p(signal+noise)}{p(noise)} + \frac{1}{4\pi}\right) \\
\end{eqnarray}

and we notice that $p(noise|d_\beta)$ is a constant independent of the source position and will be normalized away. We also not that we've set the somewhat ambiguously defined $p(\theta,\phi|d_\beta,noise)=1/4\pi$, so that it is constant over the entire sky. This is done so that if $B\ll1$, the posterior approaches a constant (and therefore uniformative) distribution. In this way, when there is little evidence for signal in the data, the contribution of this frequency bin is simply a constant independent of $(\theta,\phi)$. We do introduce the prior odds in this expression, which are difficult to determine. However, we can set them to some small number so that the data must be very informative for us to consider a model with $signal+noise$ over a model with only $noise$. By taking the product of over all frequency bins, we consider every possible combination of signal/no-signal in the frequency bins.

With either choice, we can naturally downselect the frequency bins in our model to contain only those that are likely to have signal based on the observed data. This eliminates our problem of having too many parameters.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Example: one polarization, two detectors}

For a single polarization, $A_{jk}=A \rightarrow (A^{-1}) = 1/A$. Therefore, we can write our estimator as

\begin{equation}
\hat{h} = \frac{1}{A}B_\beta d_\beta = \left( \sum\limits_{\alpha}\frac{F_\alpha F_\alpha^\ast}{S_\alpha}\right)^{-1} \sum\limits_\beta \frac{F_\beta^\ast d_\beta}{S_\beta}
\end{equation}

If we assume there are only two detectors with identical noise (H,L), then we have

\begin{equation}
\hat{h} = \frac{F_H^\ast d_H + F_L^\ast d_L}{|F_H|^2 + |F_L|^2} = h + \frac{F_H^\ast n_H + F_L^\ast n_L}{|F_H|^2 + |F_L|^2} 
\end{equation}

This means that the maximum likelihood statistic can be written as

\begin{equation}
\log \mathcal{L} = \frac{\left|F_H^\ast d_H + F_L d_L^\ast\right|^2}{S\left(|F_H|^2 + |F_L|^2\right)}
\end{equation}

which is weird. We notice that there may be a very strong dependence on the source direction, which comes from amplitude-consistency checks between H and L. These checks are possible because $N_{ifos} > N_{p}$. Perhaps more interestingly, we can consider the marginalization with a uniform prior on $h$. The posterior for $(\theta,\phi)$ in this case is

\begin{equation}
p(\theta,\phi|d_\beta) = p(\theta, \phi) \mathrm{exp}\left( \frac{\left|F_H^\ast d_H + F_L d_L^\ast\right|^2}{S\left(|F_H|^2 + |F_L|^2\right)} \right) \left[2\pi\frac{S/2}{|F_H|^2 + |F_L|^2}\right]
\end{equation}

Notice that the term in the brackets decreases when the antenna patterns increase. This means that with a uniform prior in $h$, the marginalization prefers positions with low antenna patterns. This is because the errors are larger in those regions, so the marginalization picks up more weight. If we instead use a gaussian prior on $h$ such that

\begin{equation}
p(h) \propto \mathrm{exp} \left( h^\ast Z h \right) = \mathrm{exp} \left( |h|^2/2\sigma^2 \right)
\end{equation}

we can write the posterior as

\begin{eqnarray}
p(\theta,\phi|d_\beta) & = & p(\theta, \phi) \mathrm{exp}\left( \frac{\left|F_H^\ast d_H + F_L d_L^\ast\right|^2}{S\left(|F_H|^2 + |F_L|^2\right)} \right) \left[2\pi\frac{S/2}{|F_H|^2 + |F_L|^2}\right] \nonumber \\
                       &   & \times\ \mathrm{exp}\left( -h^\ast Z h + h^\ast\frac{Z^2}{A+Z} h \right)\sqrt{\frac{A}{A+Z}}
\end{eqnarray}

and the modification to the poserterior is

\begin{equation}
\mathrm{exp}\left( -\frac{|\hat{h}|^2}{2\sigma^2}\frac{|F_H|^2+|F_L|^2}{|F_H|^2+|F_L|^2+S/2\sigma^2}\right) \sqrt{\frac{|F_H|^2+|F_L|^2}{|F_H|^2+|F_L|^2 + S/2\sigma^2}}
\end{equation}

Importantly, we see that this factor seems reasonable. For each location, the numerator in the exponential's argument should be roughly the same. This means that for larger antenna patterns, the gaussian widthd increases and there is more weight assigned to that location. This gaussian weighting should overwhelm the contribution from marginalization without a prior with appropriate $\sigma$. Therefore, we expect the posterior to follow the antenna patterns for appropriate choice of $\sigma$.\footnote{Note that in the limit of $\sigma\rightarrow\infty$, we recover the posterior obtained with a uniform prior on $h$, as expected.}

If we additionally assume that there is only one detector, then this further simplifies to

\begin{equation}
\mathrm{exp}\left( -\frac{|d|^2}{2\sigma^2}\frac{|F|^2}{|F|^2+S/2\sigma^2}\right)\sqrt{\frac{|F|^2}{|F|^2+S/2\sigma^2}}
\end{equation}

Here, it is entirely clear that regions with large antenna patterns (with respect to $S/2\sigma^2$) are favored. This gives us modulation along the antenna patterns controlled by one parameter: $\sigma$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Example: N polarizations, N detectors}

In this example we show that the likelihood contribution ($\hat{h}_k^\ast A_{kj} \hat{h}_j$) is degenerate across the entire sky when $N_{ifo} = N_{p}$, regardless of whether $A$ is singular. This is a proof by example with the $N=2$ case.

Here, we have

\begin{equation}
d_\beta B_{\beta j} = d_A \frac{F_{Aj}}{S_A} + d_B \frac{F_{Bj}}{S_B} = (S_A S_B)^{-1} (d_A S_B F_{Aj} + d_B S_A F_{Bj})
\end{equation}

This means that

\begin{eqnarray}
\hat{h}_k^\ast A_{kj} \hat{h}_j & = & d_\beta B_{\beta j} \left(A^{-1}\right)_{jk} B_{\alpha k} d_\alpha \\
                                & = & (S_A S_B)^{-2} \left[ |d_A|^2 S_B^2 F_{Aj} \left(A^{-1}\right)_{jk} F_{Aj}^\ast + d_A d_B^\ast S_A S_B F_{Aj} \left(A^{-1}\right)_{jk} F_{Bk}^\ast + (A\leftrightarrow B)\right] \\
\end{eqnarray}

Now, we can consider the implicit sums separately. First, we have

\begin{eqnarray}
F_{Aj} \left(A^{-1}\right)_{jk} F_{Aj}^\ast & = & (A_{00}A_{11}-A_{01}A_{10})^{-1}\left( F_{A0}A_{11}F_{A0}^\ast + F_{A1}A_{00}F_{A1}^\ast - F_{A0}A_{01}F_{A1}^\ast - F_{A1}A_{10}F_{A0}^\ast \right) \\
& = & (A_{00}A_{11}-A_{01}A_{10})^{-1}(S_A S_B)^{-1}\left( |F_{A0}|^2(S_B|F_{A1}|^2 + S_A|F_{B1}|^2) \right.\\
&  & \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ + |F_{A1}|^2(S_B|F_{A0}|^2 + S_A|F_{B0}|^2) \\
&  & \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ - F_{A0}F_{A1}^\ast(S_B F_{A0}^\ast F_{A1} + S_A F_{B0}^\ast F_{B1}) \\
&  & \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \left. - F_{A1}F_{A0}^\ast(S_B F_{A1}^\ast F_{A0} + S_A F_{B1}^\ast F_{B0}) \right) \\
& = & (A_{00}A_{11}-A_{01}A_{10})^{-1}(S_B)^{-1}\left( |F_{A0}|^2|F_{B1}|^2 + |F_{A1}|^2|F_{B0}|^2 \right. \\
&   & \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \left. - F_{A0}F_{A1}^\ast F_{B0}^\ast F_{B1} - F_{A0}^\ast F_{A1} F_{B0} F_{B1}^\ast \right) \\
\end{eqnarray}

Now, expanding the determinant of $A$ yields

\begin{equation}
A_{00}A_{11}-A_{01}A_{10} = (S_A S_B)^-1 \left[ |F_{A0}|^2|F_{B1}|^2 + |F_{A1}|^2|F_{B0}|^2 - F_{A0}F_{A1}^\ast F_{B0}^\ast F_{B1} - F_{A0}^\ast F_{A1} F_{B0} F_{B1}^\ast \right]
\end{equation}

so we have

\begin{eqnarray}
F_{Aj} \left(A^{-1}\right)_{jk} F_{Aj}^\ast & = & (S_A S_B)^-1 \left[ |F_{A0}|^2|F_{B1}|^2 + |F_{A1}|^2|F_{B0}|^2 - F_{A0}F_{A1}^\ast F_{B0}^\ast F_{B1} - F_{A0}^\ast F_{A1} F_{B0} F_{B1}^\ast \right] \\
                                            &   & \times (S_B)^{-1}\left( |F_{A0}|^2|F_{B1}|^2 + |F_{A1}|^2|F_{B0}|^2 - F_{A0}F_{A1}^\ast F_{B0}^\ast F_{B1} - F_{A0}^\ast F_{A1} F_{B0} F_{B1}^\ast \right) \\
& = & S_A \\
\end{eqnarray}

which is a remarkable simplification. Furthermore, we can expand the second implicit sum as

\begin{eqnarray}
F_{Aj} \left(A^{-1}\right)_{jk} F_{Bk}^\ast & = & (A_{00}A_{11}-A_{01}A_{10})^{-1}\left( F_{A0}A_{11}F_{B0}^\ast + F_{A1}A_{00}F_{B1}^\ast - F_{A0}A_{01}F_{B1}^\ast - F_{A1}A_{10}F_{B0}^\ast \right) \\
& = & (A_{00}A_{11}-A_{01}A_{10})^{-1} (S_A S_B)^{-1} \left( F_{A0}F_{B0}( S_B|F_{A1}|^2 + S_A|F_{B1}|^2) \right.\\
& = & \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ + F_{A1}F_{B1}^\ast(S_B|F_{A0}|^2 + S_A|F_{B0}|^2) \\
&  & \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ - F_{A0}F_{B1}^\ast(S_B F_{A0}^\ast F_{A1} + S_A F_{B0}^\ast F_{B1}) \\
&  & \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \left. - F_{A1}F_{B0}^\ast(S_B F_{A1}^\ast F_{A0} + S_A F_{B1}^\ast F_{B0}) \right) \\
& = & 0 
\end{eqnarray}

and we see that this term simplifies even more. We can then write the total term as

\begin{eqnarray}
\hat{h}_k^\ast A_{kj} \hat{h}_j & = & d_\beta B_{\beta j} \left(A^{-1}\right)_{jk} B_{\alpha k} d_\alpha \\
& = & (S_A S_B)^{-2} \left[ |d_A|^2 S_B^2 S_A + |d_B|^2 S_A^2 S_B \right] \\
& = & \frac{|d_A|^2}{S_A} + \frac{|d_B|^2}{S_B}
\end{eqnarray}

and we see that the maximum likelihood estimator exactly reproduces the observed data, rendering the likelihood to a statement about the probability of gaussian noise generating the observed data. This is, clearly, uniform over the entire sky and uniformative.

While this is only proof for the $N_{ifo}=N_{p}=2$ case, it should be generic whenever $N_{ifo}=N_{p}$.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Example: 2 polarizations, 2 (nearly aligned) detectors}

If we have two nearly aligned detectors and work in the dominant polarization frame, we can write

\begin{equation}
A_{ij} = s_i \delta_{ij}\ |\ s_0 \gg s_1 \cap s_0+s_1 = \frac{F_{A0}^2 + F_{A1}^2}{S_A} + \frac{F_{B0}^2+F_{B1}^2}{S_B}
\end{equation}

Notice that as long as $s_1 \geq 0$ the network is still sensitive to \emph{both} polarizations. This means that without a prior on the singal ($h_j$), the likelihood will be degenerate across the entire sky. This is because we can always find some combination of reconstructed strains that will exactly reproduce the observed data streams.

However, if we apply even a simple gaussian prior with zero-mean, we can break this degeneracy. This is equivalent to claiming that small-amplitude signals are more likely than large-amplitude signals, which is not an unreasonable statment.

Let us assume a simple gaussian as the prior on $h_j$:

\begin{equation}
Z_{jk} = z \delta_{ij} = \frac{1}{2\sigma^2} \delta_{ij}
\end{equation}

and note that this prior is independent of the coordinate system chosen, ie: it is invarient under changes in $\psi$. If this is the case, then marginalization yields a simple posterior

\begin{eqnarray}
p(\theta, \phi| d_\beta) & = & p(\theta,\phi) \prod\limits_f \mathrm{exp}\left( \hat{h}_j^\ast \left( \left(A-Z\right)_{jk} + Z_{jm} \left(A+Z\right)^{-1}_{mn} Z_{nk} \right) \hat{h}_k \right) \sqrt{(2\pi)^{N_p} \left|\left(A+Z\right)^{-1}_{jk}\right|} \\
& = & p(\theta,\phi) \prod\limits_f \mathrm{exp}\left( \hat{h}_j^\ast \left( \left(s_j-z\right) + \left(\frac{z^2}{s_j+z}\right) \right)\delta_{jk} \hat{h}_k \right) \sqrt{(2\pi)^{N_p} \prod\limits_j (s_j+z)^{-1}} \\
& = & p(\theta,\phi) \prod\limits_f \mathrm{exp}\left( \hat{h}_j^\ast \left( \frac{s_j^2}{s_j+z} \right)\delta_{jk} \hat{h}_k \right) \sqrt{(2\pi)^{N_p} \prod\limits_j (s_j+z)^{-1}}
\end{eqnarray}

We can separate this into separate components, each depending on only a single polarization. We then have, writing the estimators explicitly in terms of the data

\begin{eqnarray}
p(\theta,\phi|d_\beta)_j & = & \prod\limits_f \mathrm{exp}\left( \left|\frac{B_{j\beta}d_\beta}{s_j}\right|^2 \left( \frac{s_j^2}{s_j+z} \right) \right) \sqrt{(2\pi)^{N_p} (s_j+z)^{-1}} \\
                         & = & \prod\limits_f \mathrm{exp}\left( \frac{\left|B_{j\beta}d_\beta\right|^2}{s_j+z} \right) \sqrt{(2\pi)^{N_p} (s_j+z)^{-1}} \\
                         & = & \prod\limits_f \mathrm{exp}\left( \left|\frac{F_{jA}}{S_A} d_A + \frac{F_{jB}}{S_B} d_B\right|^2\left(s_j+z\right)^{-1} \right) \sqrt{(2\pi)^{N_p} (s_j+z)^{-1}}
\end{eqnarray}

Furthermore, if we assume the detectors have similar noise curves so that $S_A = S_B = S$, we can simplify further.

\begin{eqnarray}
p(\theta,\phi|d_\beta)_j & = & \prod\limits_f \mathrm{exp}\left( \left|F_{jA} \frac{d_A}{\sqrt{S}} + F_{jB} \frac{d_B}{\sqrt{S}}\right|^2 \frac{1}{S\left(s_j+z\right)} \right) \sqrt{(2\pi)^{N_p} (s_j+z)^{-1}} \\
                         & = & \prod\limits_f \mathrm{exp}\left( \frac{\left|F_{jA} \frac{d_A}{\sqrt{S}} + F_{jB} \frac{d_B}{\sqrt{S}}\right|^2}{\mathbb{F}_j+S/2\sigma^2} \right) \sqrt{(2\pi)^{N_p} \frac{S}{\mathbb{F}_j+S/2\sigma^2}}
\end{eqnarray}

where $\mathbb{F}_j \equiv S\cdot s_j \sim O(1)$ for the large eigenvalue and $\mathbb{F}_j \ll 1$ for the small eigenvalue. We can now, naturally, explore what happens when we turn this prior on and off, which corresonds to $2\sigma^2 \leq S$ and $2\sigma^2 \gg S$, respectively.

If the \emph{prior is turned off} ($2\sigma^2 \gg S$), we obtain

\begin{equation}
p(\theta,\phi|d_\beta)_j = \prod\limits_f \mathrm{exp}\left( \frac{\left|F_{jA} \frac{d_A}{\sqrt{S}} + F_{jB} \frac{d_B}{\sqrt{S}}\right|^2}{\mathbb{F}_j} \right) \sqrt{(2\pi)^{N_p} \frac{S}{\mathbb{F}_j}}
\end{equation}

and if $\mathbb{F}_j \ll 1$, then we can also expect $F_{j\beta}\ll 1$ in this coordinate system. Similarly if $\mathbb{F}_j\gg 1$. This means that the exponential factor will stay roughly of order unity and there is a strong degeneracy between all sky postions, modulated only by the marginalization which prefers regions with low antenna patterns.

However, if the \emph{prior is turned on} ($\mathbb{F}_0 \gg S/2\sigma^2 \gg \mathbb{F}_1$), we obtain

\begin{eqnarray}
p(\theta,\phi|d_\beta)_0 & = & \prod\limits_f \mathrm{exp}\left( \frac{\left|F_{0A} \frac{d_A}{\sqrt{S}} + F_{0B} \frac{d_B}{\sqrt{S}}\right|^2}{\mathbb{F}_0} \right) \sqrt{(2\pi)^{N_p} \frac{S}{\mathbb{F}_0}} \\
p(\theta,\phi|d_\beta)_1 & = & \prod\limits_f \mathrm{exp}\left( \frac{\left|F_{1A} \frac{d_A}{\sqrt{S}} + F_{1B} \frac{d_B}{\sqrt{S}}\right|^2}{S/2\sigma^2} \right) \sqrt{(2\pi)^{N_p} 2\sigma^2} \\
\end{eqnarray}

and the degeneracy between the two polarizations is clearly broken. We see that the large eigenvalue behaves essentially as if the prior was turned off, but the probability of having signal in the small eigenvalue is surpressed \emph{exponentially} because $|F_{1\beta}|^2 \ll S/2\sigma^2$.

What this means is that the total posterior will favor locations in which the reconstructed signal is consistent with a \emph{single polarization}, rather than two polarizations. The weight which would have come from reconstructed signal in the small eigenvalue polarization is surpressed by the prior. \footnote{This is related to one of the original motivations for Coherent WaveBurst ``regulators,'' although this formulation is somewhat better motivated than the ad hoc implementation of that algorithm.} 

\emph{Therefore, we expect the network to behave as if there were only a single polarization with two detectors when we apply this prior.} If the small eigenvalue is small over most of the sky, as is the case for nearly aligned detectors, then it's contribution to the total posterior is a factor near unity over the entire sky and any modulation in the posterior will be due to the reconstruction of the large eigenvalue polarization \emph{only}. In effect, we should get the triangulation and amplitude consistency checks that naturally occur whenever $N_{ifo} > N_p$ without this being strictly true.\footnote{A more realistic prior decomposed into a sum of gaussians should give a similar result, although the algebra may be significantly more complicated.}

We should note that we specified a rather specific prior: $\mathbb{F}_0 \gg S/2\sigma^2 \gg \mathbb{F}_1$. This prior says that the majority of signals are \emph{not detectable} because they are well below the noise floor. However, the wings of the distribution do extend to large enough strains where they are significantly larger than the minimum eigenvalue. Because the minimum eigenvalue can be made to vanish exactly for all source locations (aligned detectors), there should be some wiggle-room when defining the prior in practice. We can also define a variable width depending of frequency ($\sigma(f)$) without complicating this derivation. 

We should also keep in mind that this analysis concerned nearly aligned detectors, and 2 mis-aligned detectors may behave differently.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{triangulation and effective priors}

We now discuss how some ``common sense'' sky localization algorithms fall out of this formalism. These include \emph{triangulation} and \emph{effective priors} on the source's location $(\theta,\phi)$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{triangulation}
Most ``back-of-the-envelop'' estimates of sky localization rely on \emph{triangulation} using spatially separated detectors. Essentially, this is the most basic form of amplitude consistency between the detectors. An observer assumes they can associate a wiggle in one detector with a wiggle in another detector, and the difference in the times at which those wiggle occured corresponds to the time-of-flight for the wave-front to travel from one detector to the other. This is indeed a useful concept, but it is not always applicable. In particular, it relies on the fact that an observe \emph{can confidently associate} a wiggle in one detector with a wiggle in another detector. This is equivalent to an assumption that they can identify and associate parts of the gravitational-wave signal as seen in different detectors. Also, because triangulation is essentially an amplitude check (time-of-arrivals of an identifiable portion of the gravitational wave), it behaves like a \emph{likelihood} in the bayesian sense.

However, this can only be done when $N_{ifo} > N_{p}$, which is the general requirement for amplitude consistency. If $N_{ifo} < N_p$, the network will be insensitive to some of the polarizations and we should expect $N_{ifo} = \left(N_p\right)_{\mathrm{eff}}$. When $N_{ifo} = N_p$, there is a one-to-one transformation that can recreate the observed data streams with some combination of polarizations \emph{for each point in the sky}. Therefore, observers cannot confidently determine whether the wiggle observed in one detector comes from \emph{the same part of the gravitational wave} as a wiggle in another detector. That means triangulation is not possible and leads to a degenerate likelihood over most of the sky.

Fortunately, the LIGO detectors are nearly aligned, which means they are effectively sensitive to a single polarization over most of the sky. Therefore, for a LHO-LLO network, $N_{ifo}=2 > 1=\left(N_p\right)_{\mathrm{eff}}$. Similarly, for the LHO-LLO-Virgo network, we have 3 detectors and the condition is satisfied as well. We see that the naive assumption that triangulation will always work is fortuitously true for the actual detector networks.

We should also note that triangulation gives very different error regions depending on $N_{ifo}$ and $\left(N_{p}\right)_{\mathrm{eff}}$. For the LHO-LLO network, the locus of points that gives a consistent time-of-arrival using a single polarization is an annulus. This annulus can be a great circle and will typically contain a large portion of the sky. The annulus's width is controlled by the accuracy to which observers can determine the time-of-flight between detectors. For the LHO-LLO-Virgo netowrk, assuming all three detectors participate, triangulation gives 2 points in the sky, which reflects a symmetry with respect to reflection about the plane defined by the three detectors. We expect the error region to consist of blobs centered around these points, with the blob radius determined by the accuracy to which we measure time-of-flight between the various pairs of detectors.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\subsubsection{analytic triangulation for 2 detectors}
%
%If we assume there are only 2 detectors, then we can write the \emph{likelihood} component of the posterior as
%
%\begin{eqnarray}
%\hat{h}_j^\ast A_{jk} \hat{h}_k & = & \left( d_A B_{Ak} + d_B B_{Bk} \right) \left(A^{-1}\right)_{kj} \left( d_A^\ast B_{Ak}^\ast + d_B^\ast B_{Bk}^\ast \right) \\
%& = & |d_A|^2 B_{Ak} \left(A^{-1}\right)_{kj} B_{Aj}^\ast + |d_B|^2 B_{Bk} \left(A^{-1}\right)_{kj} B_{Bj}^\ast \\
%& = & + 2\mathbb{R}\left\{ d_A d_B^\ast B_{Ak} \left(A^{-1}\right)_{kj} B_{Bj} \right\} \\
%\end{eqnarray}
%
%and if we define $B_{\alpha k} = F_{\alpha k}/S_\alpha = \mathcal{F}_{\alpha k}e^{-2\pi i f \Delta t} / S_\alpha = C_{\alpha k} e^{-2\pi i f \Delta t}$, we can write this as
%
%\begin{eqnarray}
%\hat{h}_j^\ast A_{jk} \hat{h}_k & = & |d_A|^2 C_{Ak} \left(A^{-1}\right)_{kj} C_{Aj} + |d_B|^2 C_{Bk} \left(A^{-1}\right)_{kj} C_{Bj} \\
%& = & + 2 C_{Ak} \left(A^{-1}\right)_{kj} C_{Bj} \cdot \mathbb{R}\left\{d_A d_B^\ast e^{-2\pi i f \left(\Delta t_A - \Delta t_B\right) }\right\} \\
%\end{eqnarray}
%
%Already, we can clearly see that there is an oscilatory term that compares the time-shifted signal (embedded in the data) and the expected time-shift. This oscillatory term either adds to the log-likelihood if the time shift is about right or it subtracts from the likelihood if the shift is very wrong.
%
%To investigate further, let us restrict ourselves to the case of a single polarization and consider the case where $F_{\alpha}h \gg n_\alpha$ (high snr). We can then write
%
%\begin{eqnarray}
%\hat{h}_j^\ast A_{jk} \hat{h}_k & = & \frac{1}{A}\left( \left|\frac{d_A \mathcal{F}_A}{S_A}\right|^2 + \left|\frac{d_B \mathcal{F}_B}{S_B}\right|^2 \right. \\
%&  & \left. + 2 \frac{\mathcal{F}_{A} \mathcal{F}_{B}}{S_A S_B} \mathbb{R}\left\{d_A d_B^\ast e^{-2\pi i f \left(\Delta t_A - \Delta t_B\right) }\right\}\right) \\
%& = & \frac{1}{A}\left( \left|\frac{h \mathcal{F}_A^2}{S_A}\right|^2 + \left|\frac{h \mathcal{F}_B^2}{S_B}\right|^2 \right. \\
%&  & \left. + 2 \frac{|h \mathcal{F}_{A} \mathcal{F}_{B}|^2}{S_A S_B} \mathbb{R}\left\{e^{+2\pi i f\left(\left(\delta t_A\right)_{src} - \left(\Delta t_B\right)_{src}\right)} e^{-2\pi i f \left(\Delta t_A - \Delta t_B\right) }\right\}\right) \\
%& = & \frac{|h|^2}{A}\left( \left|\frac{\mathcal{F}_A^2}{S_A}\right|^2 + \left|\frac{\mathcal{F}_B^2}{S_B}\right|^2 \right. \\
%&  & \left. + 2 \frac{|\mathcal{F}_{A} \mathcal{F}_{B}|^2}{S_A S_B} \cos\left(2\pi f\left(\delta t - \left(\delta t\right)_{src}\right)\right)\right)
%\end{eqnarray}
%
%Now, the total likelihood contains the integral of this quantity over all frequencies
%
%\begin{eqnarray}
%\log\mathcal{L} & \supset & \int\mathrm{d}f\, \hat{h}_j^\ast A_{jk} \hat{h}_k \\
%& = & \int\mathrm{d}f\, \frac{|h|^2}{A}\left( \left|\frac{\mathcal{F}_A^2}{S_A}\right|^2 + \left|\frac{\mathcal{F}_B^2}{S_B}\right|^2 \right. \\
%&   & \ \ \left. + 2 \frac{|\mathcal{F}_{A} \mathcal{F}_{B}|^2}{S_A S_B} \cos\left(2\pi f\left(\delta t - \left(\delta t\right)_{src}\right)\right)\right)\\ 
%\end{eqnarray}
%
%We can see that there will always be positive support when $\delta t - \left(\delta t\right)_{src}\sim 0$ because the frequency dependence of that oscillatory term cancels. This corresponds to the \emph{main} triangulation ring. However, if the gravitational wave can be approximated as $h(f) \sim h(f_o)\cdot(\Theta(f-f_o+\epsilon) - \Theta(f-f_o-\epsilon))$, and that the noise spectra are nearly constant in this bandwidth, then we can approximate the integrals as follows.
%
%\begin{eqnarray}
%\log\mathcal{L} & \supset & \frac{|h(f_o)|^2}{A(f_o)}\left( \left|\frac{\mathcal{F}_A^2}{S_A(f_o)}\right|^2 + \left|\frac{\mathcal{F}_B^2}{S_B(f_o)}\right|^2\right) 2\epsilon \\
%&  & + 2\frac{|h(f_o)|^2}{A(f_o)} \frac{|\mathcal{F}_{A} \mathcal{F}_{B}|^2}{S_A(f_o) S_B(f_o)}\frac{1}{2\pi \left(\delta t - \left(\delta t\right)_{src}\right)} \left( \sin\left(2\pi (f_o-\epsilon) \left(\delta t - \left(\delta t\right)_{src}\right)\right) - \sin\left(2\pi (f_o-\epsilon) \left(\delta t - \left(\delta t\right)_{src}\right)\right) \right) \\
%& \supset & 2\frac{|h(f_o)|^2}{A(f_o)} \frac{|\mathcal{F}_{A} \mathcal{F}_{B}|^2}{S_A(f_o) S_B(f_o)}\frac{2}{2\pi \left(\delta t - \left(\delta t\right)_{src}\right)} \cos\left(2\pi f_o \left(\delta t - \left(\delta t\right)_{src}\right)\right)\sin\left(2\pi \epsilon \left(\delta t - \left(\delta t\right)_{src}\right)\right) \\
%\end{eqnarray}
%
%and we notice that there are now two oscillatory contributions from $\delta t - \left(\delta t\right)_{src}$. However, note that there is a \emph{non oscillatory} contribution from $\delta t - \left(\delta t\right)_{src}$, which breaks the total periodicity of the function. Therefore, we would in general only expect weight to accumulate when $\delta t - \left(\delta t\right)_{src}\sim 0$. There is an important exception to this conclusion, which occurs in the limit when $f_o \gg \epsilon$, so that the first oscillatory component can execute several cylces before the second's argument changes much. In this limit, we can expand the second oscillatory function, which yields
%
%\begin{eqnarray}
%\log\mathcal{L} & \supset & 2\frac{|h(f_o)|^2}{A(f_o)} \frac{|\mathcal{F}_{A} \mathcal{F}_{B}|^2}{S_A(f_o) S_B(f_o)}\frac{2}{2\pi \left(\delta t - \left(\delta t\right)_{src}\right)} \cos\left(2\pi f_o \left(\delta t - \left(\delta t\right)_{src}\right)\right)\sin\left(2\pi \epsilon \left(\delta t - \left(\delta t\right)_{src}\right)\right) \\
%& \sim & 2\frac{|h(f_o)|^2}{A(f_o)} \frac{|\mathcal{F}_{A} \mathcal{F}_{B}|^2}{S_A(f_o) S_B(f_o)}\frac{2}{2\pi \left(\delta t - \left(\delta t\right)_{src}\right)} \cos\left(2\pi f_o \left(\delta t - \left(\delta t\right)_{src}\right)\right)2\pi \epsilon \left(\delta t - \left(\delta t\right)_{src}\right) + O(\epsilon^3) \\
%& \sim & 4\epsilon\frac{|h(f_o)|^2}{A(f_o)} \frac{|\mathcal{F}_{A} \mathcal{F}_{B}|^2}{S_A(f_o) S_B(f_o)}\cos\left(2\pi f_o \left(\delta t - \left(\delta t\right)_{src}\right)\right) + O(\epsilon^3) \\
%\end{eqnarray}
%
%and we see that the non-oscillatory component has cancelled. Therefore, in this limit we obtain an oscillatory function, with multiple nearly equivalent peaks. These correspond to \emph{fringe peaks} in the posterior, and the angular separation between such finges is determined by $\cos\delta\theta \sim 1/f_o$. 
%
%\emph{This means that we should expect fringe peaks whenever $f_o \gg \epsilon$.} We can predict with the existence of fringe peaks with knowledge of the waveform, or we can infer something about the waveform by observing the fringe peaks.
%
%We should also note that in the \emph{dominant polarization frame}, the likelihood will break into separate pieces without any off-diagonal components. We can then analyze a 2-detector, $N_p$ polarization network as $N_p$ 2-detector, 1 polarization networks. The form of the oscillatory function will be the same for all polarizations, with different pre-factors. 
%
%We might also hope that we can analyze a $N_{ifo}$-detector, $N_{p}$-polarization network by breaking it up into $\left(\begin{matrix}N_{ifo}\\2\end{matrix}\right)$ 2-detector, $N_p$-polarization networks. We may then observe more complicated fringe patterns arrising from the intersection of the rings produced by each of the 2-detector combinations. While amplitude consistency may help break some degeneracy when $N_{ifo}>N_{p}$, this at least gives us intuition regarding the posterior's morphology.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{analtyic triangulation for N detectors}

Assuming we decompose the prior on $h_j$ into a sum of gaussians, the posterior probability will be a sum of exponentials, each of which contains terms like

\begin{eqnarray}
\log p(\theta,\phi|d_\beta) & \supset & \int\mathrm{d}f\, \hat{h}^\ast_k \left( A - Z + Z\left(A+Z\right)^{-1}Z \right)_{kj}\hat{h}_j \\
& = & \int\mathrm{d}f\, d_\beta^\ast B_{\beta m}^\ast \left(A^{-1}\right)_{mk}^\ast \left( A - Z + Z\left(A+Z\right)^{-1}Z \right)_{kj} \left(A^{-1}\right)_{jn} B_{\alpha n} d_\alpha \\
\end{eqnarray}

Now, we can define $B_{\beta m} = C_{\beta m} \mathrm{exp}(+2\pi i f \Delta t_\alpha)$, where we explicitly separate the time-delay from the noise weighted antenna pattern. We should note that any change of basis concerning the polarizations we reconstruct will act on the $C_{\beta m}$ and will not touch this time-delay. Using this, we can then write

\begin{eqnarray}
\log p(\theta,\phi|d_\beta) & \supset & \int\mathrm{d}f\, \left(C_{\beta m}^\ast \left(A^{-1}\right)_{mk}^\ast \left( A - Z + Z\left(A+Z\right)^{-1}Z \right)_{kj} \left(A^{-1}\right)_{jn} C_{\alpha n}\right) \left(d_\beta^\ast d_\alpha e^{+2\pi i f (\Delta t_\alpha - \Delta t_\beta)}\right) \\
\end{eqnarray}

The dependence on source position manifests in several ways. The term in the first parentheses is a complicated combination of the prior, antenna patterns (without time-delays) and noise spectra. We expect this to vary like the antenna patterns for most of the sky, which is generally quite slow. The term in the second parentheses depends on the time-of-flight between the pairs of detectors. In particular, the time-of-flight appears as an oscillatory term which can vary quickly when the frequency ($f$) is large, even when the actual change in the time-of-flight is relatively small. We expect triangulation to come from these second terms. In fact, we can write some of the sums explicitly, which will somewhat clarify the structure of this expression.

\begin{eqnarray}
\log p(\theta,\phi|d_\beta) & \supset & \int\mathrm{d}f\, \sum\limits_{\alpha} \left(C_{\alpha m} \left(A^{-1}\right)_{mk} \left( A - Z + Z\left(A+Z\right)^{-1}Z \right)_{kj} \left(A^{-1}\right)_{jn} C_{\alpha n}\right) \left(d_\alpha^\ast d_\alpha \right) \\
& & + \int\mathrm{d}f\,\sum\limits_{\alpha\neq\beta} \left(C_{\beta m}^\ast \left(A^{-1}\right)_{mk}^\ast \left( A - Z + Z\left(A+Z\right)^{-1}Z \right)_{kj} \left(A^{-1}\right)_{jn} C_{\alpha n}\right) \left(d_\beta^\ast d_\alpha e^{+2\pi i f (\Delta t_\alpha - \Delta t_\beta)}\right) \\ 
\end{eqnarray}

We see that the only \emph{fast} dependence comes from terms with $\alpha\neq\beta$, and in particular these appear in pairs of detectors, independently of the basis used for the gravitational wave polarizations. In fact, we can make the following definition to simplify the following equations

\begin{equation}
M_{\alpha\beta} \equiv C_{\alpha m} \left(A^{-1}\right)_{mk} \left( A - Z + Z\left(A+Z\right)^{-1}Z \right)_{kj} \left(A^{-1}\right)_{jn} C_{\beta n}
\end{equation}

so that 

\begin{eqnarray}
\log p(\theta,\phi|d_\beta) & \supset & \int\mathrm{d}f\, \sum\limits_{\alpha} M_{\alpha\alpha} \left(d_\alpha^\ast d_\alpha \right) \\
& & + \int\mathrm{d}f\,\sum\limits_{\alpha\neq\beta} M_{\beta\alpha} \left(d_\beta^\ast d_\alpha e^{+2\pi i f (\Delta t_\alpha - \Delta t_\beta)}\right) \\ 
\end{eqnarray}

We might be tempted to assign meaning to these two terms. The first term looks like an amplitude consistency term, because it checks the amplitudes in each detector separately, while the second term looks like a triangulation term, because it dependes strongly on the time-of-flight errors. This is not quite correct, because the MLE $\hat{h}_j$ puts amplitude consistency into both terms. However, we can safely say that triangulation comes from the second term, which is composed of all possible pairs of detectors. We then see that we can analyze triangulation with $N_{ifo}$ detectors as $\left(\begin{matrix}N_{ifo}\\2\end{matrix}\right)$ pairs of detectors. Now, in the limit of high SNR ($Fh \gg n$), we expect the data to have the form

\begin{equation}
d_\beta \sim \left( \mathcal{F}_{\beta j} h_j \right) e^{-2\pi i f \left(\Delta t_\beta\right)_o} \equiv D_\beta e^{-2\pi i f \left(\Delta t_\beta\right)_o}
\end{equation}

where $\left(\Delta t_\beta\right)_o$ is the time shift from the actual location. Inserting this into our expression for the likelihood, we obtain

\begin{eqnarray}
\log p(\theta,\phi|d_\beta) & \supset & \int\mathrm{d}f\,\sum\limits_{\alpha\neq\beta} M_{\beta\alpha} \left(D_\beta^\ast D_\alpha e^{-2\pi i f\left(\left(\Delta t_\alpha\right)_o-\left(\Delta t_\beta\right)_o\right) +2\pi i f (\Delta t_\alpha - \Delta t_\beta)}\right) \\ 
\end{eqnarray}

For notation's sake, let us define $\delta t_{\alpha\beta} \equiv \left(\Delta t_\alpha - \Delta t_\beta\right) - \left(\left(\Delta t_\alpha\right)_o-\left(\Delta t_\beta\right)_o\right)$. Triangulation essentially comes from this integral, which coherently combines many different frequencies through the integral. In particular, we analyze the following two cases in more detail

\begin{enumerate}
	\item{approximately constant signal within some bandwith}
	\item{sinegaussian signal with 2 polarizations}
\end{enumerate}

For both cases, we assume the noise spectra vary slowly with frequency over the signal's bandwidth, so we can approximate the integral analytically.

In the first case, we can approximate the integral, somewhat crudely, as

\begin{eqnarray}
\log p(\theta,\phi|d_\beta) & \supset & \int\limits_{f_o-\epsilon}^{f_o+\epsilon}\mathrm{d}f\,\sum\limits_{\alpha\neq\beta} M_{\beta\alpha} \left(D_\beta^\ast D_\alpha \right)e^{+2\pi i f \delta t_{\alpha\beta}} \\
& \sim & \sum\limits_{\alpha\neq\beta} M_{\alpha\beta} D_\beta^\ast D_\alpha \left(e^{+2\pi i (f_o+\epsilon) \delta t_{\alpha\beta}} - e^{+2\pi i (f_o-\epsilon) \delta t_{\alpha\beta}}\right) \\
& = & \sum\limits_{\alpha\neq\beta} M_{\alpha\beta} \left|D_\beta D_\alpha\right| \cos\left( 2\pi f_o \delta t_{\alpha\beta} + \arctan\left(\frac{\mathbb{I}\left\{D_\beta^\ast D_\alpha\right\}}{\mathbb{R}\left\{D_\beta^\ast D_\alpha\right\}}\right) \right)\left[\frac{\sin\left(2\pi\epsilon\delta t_{\alpha\beta}\right)}{\pi\delta t_{\alpha\beta}}\right]
\end{eqnarray}

and unsurprisingly, the fourier transform of a step frunction is a sinc function. However, we also note that there is a oscillatory component, with a different frequency, multiplying the sinc function. The total function is \emph{not periodic} in $\delta t_{\alpha\beta}$. However, if we have $f_o \gg \epsilon$, then the cosine can go through many cycles before the sinc function's argument changes much. In this limit, we can expand the sinc function and the non-periodic function in the denominator cancels to first order with the sine function, yielding

\begin{equation}
\log p(\theta,\phi|d_\beta) \supset \sum\limits_{\alpha\neq\beta} M_{\alpha\beta} \left|D_\beta D_\alpha\right| \cos\left( 2\pi f_o \delta t_{\alpha\beta} + \arctan\left(\frac{\mathbb{I}\left\{D_\beta^\ast D_\alpha\right\}}{\mathbb{R}\left\{D_\beta^\ast D_\alpha\right\}}\right) \right) 2\epsilon + \epsilon \times O(\epsilon\delta t_{\alpha\beta})^2
\end{equation}

We notice that this function is periodic, and we expect there to be fringe peaks separated by $\delta t_{\alpha\beta} \propto \cos\delta\theta \sim 1/f_o$. Now, this only holds when $\epsilon \ll f_o$, and $f_o$ is large enough to perform many cycles before the antenna patterns change appreciably. If that is not the case, then we cannot neglect the dependence of $M$ and the periodicity will also be broken.

Importantly, this shows us when we should expect fringe peaks: for narrow band, high frequency signals. Intuitively, this makes sense because narrow band signals are spread out in the time domain, and high frequency signals have many cycles. Shifting the data so the signal lines up on the $n$ peaks from perfectly aligned will still yield a realtively good match, although somewhat worse. These alignments $n$ peaks from optimal correspond to the fringe peaks.

Another important example, for which we do not need to approximate the integral, is when the signal is a sinegaussian with

\begin{equation}
h_j = \left(h_j\right)_o e^{-(f-f_o)^2 \pi^2 \tau^2 + i\phi_o}
\end{equation}

In this case, we have

\begin{eqnarray}
\log p(\theta,\phi|d_\beta) & \supset & \int\mathrm{d}f\,\sum\limits_{\alpha\neq\beta} M_{\beta\alpha} \left(\mathcal{F}_{\beta j}\left(h_j\right)_o \mathcal{F}_{\alpha k}\left(h_k\right)_o \right)e^{-2(f-f_o)^2\pi^2\tau^2+2\pi i f \delta t_{\alpha\beta}} \\
& = & \sum\limits_{\alpha\neq\beta} M_{\beta\alpha} \left(\mathcal{F}_{\beta j}\left(h_j\right)_o \mathcal{F}_{\alpha k}\left(h_k\right)_o \right) e^{2\pi i f_o \delta t_{\alpha\beta}}\int\mathcal{d}x\, e^{-2x^2\pi^2\tau^2+2\pi i x \delta t_{\alpha\beta}} \\
& = & \sum\limits_{\alpha\neq\beta} M_{\beta\alpha} \left(\mathcal{F}_{\beta j}\left(h_j\right)_o \mathcal{F}_{\alpha k}\left(h_k\right)_o \right) e^{2\pi i f_o \delta t_{\alpha\beta}}\frac{1}{\sqrt{2}\tau} e^{-\frac{(\delta t_{\alpha\beta})^2}{2\tau^2}} \\
\end{eqnarray}

We note that interchanging $\alpha\leftrightarrow\beta$ is equivalent to complex conjugation, so we can simplify this as

\begin{equation}
\log p(\theta,\phi|d_\beta) \supset \sum\limits_{\alpha\neq\beta} M_{\beta\alpha} \left(\mathcal{F}_{\beta j}\left(h_j\right)_o \mathcal{F}_{\alpha k}\left(h_k\right)_o \right) \frac{1}{\sqrt{2}\tau} e^{-\frac{(\delta t_{\alpha\beta})^2}{2\tau^2}} \cos\left( 2\pi f_o \delta t_{\alpha\beta} \right)
\end{equation}

Indeed, we see that there is a sine-gaussian in the log of the posterior. The number of fringe peaks is then strongly determined by the gaussian's width in the time-domain ($\tau$) and the central frequency ($f_o$). Typically, the quality factor ($Q=\sqrt{2}\pi f_o\tau$) is used to describe this prodcut, and it roughly measures the number of cycles per e-folding. Larger Q will have more fringe peaks before the exponential envelope damps the likelihood significantly. However, we don't often see the full number of peaks because the antenna patterns change significantly before we reach more than $\sim$2-3 fringes, and then $M$ and $\mathcal{F}$ change significantly. They then damp the fringe peak. 

By taking limits of the sinegaussian, we see that gaussian signals have no fringe peaks because there is no oscillatory component. We therefore expect a single triangulation ring for gaussian signals. Similarly, wide-band sinegaussians will have fewer fringe peaks. And low frequency sinegaussians will tend to have fewer fringe peaks than their high frequencie counterparts with the same width.

We also note that $M$ has units of $1/S$, so the factor that multiplies the oscillatory function looks like a SNR ($\rho^2\sim D^\ast D/S$). Therefore, we expect the amplitude of these oscillations to scale linearly with $\rho^2$. Intepreting the leading order terms as a contribution to the Fisher information matrix, we would then expect the timing errors to scale inversely with $\rho$. 

Finally, we note that $C_{\alpha j}A^{-1}_{jk}C_{\beta k} = S_\alpha^{-1}\delta_{\alpha\beta}$ when $N_{ifo}=N_{pol}$. This means the triangulation terms cancel exactly (no fast modulation) and the slow ``amplitude consistency'' terms become independent of the source location. The only contributions we get in this case come from the marginalization over the prior. Otherwise, the posterior would be degenerate over the entire sky.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{effective priors on $(\theta,\phi)$}

Triangulation behaves like a likelihood, but we can apply further knowledge about the population of sources to compute a prior. The simplest prior on $(\theta,\phi)$ would come from the assumption that the sources live in the galactic plane, or they live near galaxies. This is a direct prior on $(\theta,\phi)$ and is not difficult to interpret.

However, we can also derive an \emph{effective} prior on $(\theta,\phi)$ using knowledge of the network sensitivity and the distribution of signal amplitudes. The concept is simple: if quiet signals are more likely than loud signals, then we are more likely to detect events where the network's large eigenvalue is in fact large. What this means is that the population of \emph{detected} events will follow the antenna patterns in a predictable way, more detected signals when the large eigenvalue is large and fewer detected signals when the large eigenvalue is small. Of course, the particular functional form the distribution of detected events takes is not obvious, but a simple estimate goes as follows:

Sources are uniformly distributed in volume, independently of their morphology or intrinsic strength. However, we can relate the observed strain to the energy in the wave and the distance through

\begin{equation}
\frac{E_{GW}}{D_L^2} \int\mathrm{d}f\, (f h_{j}^\ast)(f h_{j}) \approx f_o^2 \int\mathrm{d}f\, h_{j}^\ast h_{j}
\end{equation}

where our approximation assumes a narrow-band signal. Furthermore, working in the dominant polarization frame (so things are diagonal)

\begin{eqnarray}
h_{j}^\ast h_{j} & \approx & \hat{h}_j^\ast \hat{h}_j \\
                 & = & d_\beta^\ast B_{\beta k}^\ast \left(A^\ast\right)_{jk}^{-1} \left(A\right)_{ji}^{-1} B_{\alpha i} d_\alpha \\
                 & = & d_\beta^\ast \frac{F_{\beta j}^\ast}{S_\beta} s_j^{-2} \frac{F_{\alpha j}}{S_\alpha} d_\alpha \\
\end{eqnarray}

If we assume the detectors have similar noise curves, we can approximate this further as

\begin{eqnarray}
h_{j}^\ast h_{j} & \approx & d_\beta^\ast \frac{F_{\beta j}^\ast}{S} \left(\frac{S}{S s_j}\right)^{2} \frac{F_{\alpha j}}{S} d_\alpha \\
                 & = & d_\beta^\ast \frac{F_{\beta j}^\ast F_{\alpha j}}{\left(S s_j\right)} d_\alpha \\
\end{eqnarray}

Furthermore, $s_j\sim F^\ast F/ S \rightarrow S s_j \sim F^\ast F$, and we can make the last leap to the statement that

\begin{equation}
h_{j}^\ast h_{j} \sim \frac{1}{S s_j}
\end{equation}

Now, we if we expect the signals to be distributed uniformly in volume, we require

\begin{eqnarray}
p(D_L) \propto D_L^2 & \approx & \frac{E_{GW}/f_o^2}{\int\mathrm{d}f\, h_{j}^\ast h_{j}} \\
                     & \sim & S s_j \sim F^\ast F \\
                     & = & p_{\mathrm{eff}}(\theta,\phi)
\end{eqnarray}

However, our marginalization is over $h_j$, so we should consider $p(h)\mathrm{d}h\sim(F^\ast F)^{3/2}$ for an astrophysical population. Essentially, this argues that the likelihood is sharply peaked and we can approximate the marginalization with the value of the prior near the maximum likelihood estimate. The marginalized signal will be proportional to the antenna pattern in this way, where we really expect $F^\ast F$ to go like the maximum eigenvalue of the sensitivity matrix.

There is a considerable amount of hand-waving in this argument, and it really holds closely when $\left(N_{p}\right)_{\mathrm{eff}} = 1$, and there is only a single polarization. This is the case for the LHO-LLO network, and indeed we observe a distribution of detected signals that closely follows the predicted form. 

More complicated and/or careful arguments may produce slightly modified effective priors, but the combination of \emph{triangulation} and \emph{effective priors} actually captures a good fraction of the physics associated with localizing generic gravitational wave signals. Fully coherent methods, such as the rest of this note, can perform more thorough amplitude checks (rather than just time-of-arrival) and improve upon this estimate, and it is not clear to what extent that information can improve localization.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Extended sources}\label{section:extended sources}

\emph{Point sources} were described in Section \ref{section:point sources}. Here we consider extended sources which may come from distant parts of the sky simultaneously. This modifies the way in which the strain enters our data streams, although all we really have to do is add a few more indicies. 

\subsection{maximum likelihood estimators}

Consider the position-space integral

\begin{eqnarray}
\int \mathrm{d}\cos\theta \mathrm{d}\phi\, F_{\beta j}\left(\theta,\phi\right) h_{j}\left(\theta,\phi\right) & = & \int \mathrm{d}\cos\theta \mathrm{d}\phi\, \left( \sum\limits_{lm} Y_{lm} F_{\beta j (lm)} \right) \left( \sum\limits_{l^\prime m^\prime} Y_{l^\prime m^\prime} h_{j (l^\prime m^\prime)} \right) \\
& = & \sum\limits_{l m l^\prime m^\prime} F_{\beta j (lm)}  h_{j (l^\prime m^\prime)} \int \mathrm{d}\cos\theta \mathrm{d}\phi Y_{lm} Y_{l^\prime m^\prime} \\
& = & \sum\limits_{lm} F_{\beta j (l m)} h_{j (l m)}
\end{eqnarray}

which is the equivalent of parseval's theorem for spherical harmonics. Now, this summation is technically over an infinite series, but we can always truncate the series at high order $(l,m)$ to make this tractable. Furthermore, a similar summation is reasonable if we pixelate the sky in
to a set of discrete points. The mathematics that follows is independent of the decomposition (position-space or spherical harmonics), so we simply refer to the postion tuple with a single \emph{upper case greek letter}.


Now, our likelihood functional is modified as follows

\begin{eqnarray}
\mathcal{L} = \frac{p(d_\beta - F_{\beta j}h_j)}{p(d_\beta)} & = & \mathrm{exp}\left(\int\mathrm{d}f\, \sum_\beta \frac{\left|d_\beta\right|^2 - \left|d_\beta - F_{\beta j \Omega}h_{j \Omega}\right|^2}{S_\beta} \right) \\
                                              & = & \mathrm{exp}\left(\int\mathrm{d}f\, \sum_\beta \frac{d_\beta F_{\beta j \Omega}^\ast h_{j \Omega}^\ast + d_\beta^\ast F_{\beta j \Omega}h_{j \Omega} - h_{k \Omega} F_{\beta k \Omega} F_{\beta j \Psi}^\ast h_{j \Psi}^\ast}{S_\beta} \right)
\end{eqnarray}

where summation over sky positions $\Omega$, $\Psi$ are implied.

If we vary this functional with respect to $h^\ast_{j\Omega}$, we obtain the following Euler equations.

\begin{equation}
\sum\limits_\beta \frac{F_{\beta \Omega j}^\ast d_\beta}{S_\beta} = \sum\limits_{\beta\Psi} \frac{F_{\beta\Omega j}^\ast F_{\beta \Psi k} h_{k \Psi}}{S_\beta}
\end{equation}

and we can define analogous matricies as before

\begin{eqnarray}
A_{\Omega\Psi j k} & \equiv & \sum\limits_\beta \frac{F_{\beta\Omega j}^\ast F_{\beta \Psi k}}{S_\beta} \\
B_{\beta\Omega j} & \equiv & \frac{F_{\beta\Omega j}^\ast}{S_\beta}
\end{eqnarray}

which allows us to solve explicitly for the maximum likelihood estimator

\begin{equation}
\hat{h}_{\Psi k} = \left(A^{-1}\right)_{\Psi\Omega k j} B_{\beta \Omega j} d_\beta
\end{equation}

Note, the size of these matricies depends on the number of sky positions included. This means that the matrix inversion may be non-trivial computationally, or poorly defined in the continuum limit. However, if we limit ourselves to a finite number of sky locations this should be reasonable, if expensive.\footnote{For any practical search, we're only interested in the approximate posterior anyway. We won't be able to resolve the source perfectly in any case, so this slight pixelization should not affect the search in any meaningful way.}

Now, the errors associated with this estimator are

\begin{eqnarray}
\hat{h}_{\Psi k} & = & \left(A^{-1}\right)_{\Psi\Omega k j} B_{\beta \Omega j} \left( F_{\beta \Upsilon i} h_{i\Upsilon} + n_\beta \right) \\
                 & = & \left(A^{-1}\right)_{\Psi\Omega k j} \left( B_{\beta \Omega j} F_{\beta \Upsilon i} \right) h_{i\Upsilon} +  \left(A^{-1}\right)_{\Psi\Omega k j} B_{\beta \Omega j} n_\beta \\
                 & = & \left(A^{-1}\right)_{\Psi\Omega k j} A_{\Omega\Upsilon j i} h_{i\Upsilon} +  \left(A^{-1}\right)_{\Psi\Omega k j} B_{\beta \Omega j} n_\beta \\
\Rightarrow \hat{h}_{\Psi k} - h_{\Psi k} \equiv \epsilon_{\Psi k} & = & \left(A^{-1}\right)_{\Psi\Omega k j} B_{\beta \Omega j} n_\beta
\end{eqnarray}

and we see that the errors are gaussian around the maximum likelihood estimator.

\textcolor{red}{\textbf{NOTE THAT THE SKY POSTION AND THE POLARIZATION INDICIES LIKE TO GO TOGETHER. In particular, with this inversion we have a summation over both which yields the kroniker delta. This implies that we should group them together into a tuple of three, indexed by a single letter rather than two indicies.}}

If we plug this into our likelihood functional, we obtain the following 

\begin{equation}
\log \mathcal{L} = \int\mathrm{d}f\, d_\beta^\ast B_{\beta\Omega j}^\ast \left( A^{-1}\right)_{\Omega\Psi j k} B_{\alpha\Psi k} d_\alpha - \epsilon_{k\Omega}^\ast A_{\Omega\Psi k j} \epsilon_{\Psi k}
\end{equation}

and indeed, the probability is gaussian in the errors. Note, we are summing over all sky positions implicitly with repeated capital greek indicies. 

\subsection{posterior probabilities}

We now ask the question, how do we compute the posterior using this likelihood, and in what way is this most efficient.

\textcolor{red}{\textbf{We can decompose the posterior in either position-space or spherical harmonics. This may yield simplification of the formula to compute the posterior, but it is not immediately apparent how this comes into play.}}

Again, we can write the posterior as 

\begin{equation}
p(\Omega|d_\beta) = \int\mathcal{D}h_{j\Omega}\, \frac{p(d_\beta|h_{j\Omega}, \Omega)p(h_{j\Omega}, \Omega)}{p(d_\beta)}
\end{equation}

\textcolor{red}{and note that $\Omega$ is \emph{fixed} in the integration? Can we represent the likelihood as a sum over independent sky position/polarization channels? If that's the case, we simply have to decompose the posterior into this diagonal basis and compute each term. The total posterior will come from re-summing the decomposition. When we write $p(\Omega|d_\beta)$, we mean the posterior that the signal came from that sky postion and only that sky position? In which case, my nice summations over source location should be broken and we use a single sky position. Indeed, this seems reasonable. We can then use the \emph{point estimate} forumation from this point onward. The crucial step will be when we consider $p(\theta,\phi|d_\beta)$ after computing $p(l,m|d_\beta)$, which should simply be a re-summation weighted by spherical harmonics. There should also be strong reality constraints that should help us reduce the number of spherical harmonics that need to be considered.}

\textcolor{green}{Actually, the summation in the integrand comes from considering all possible sky postions. This is appropriate when computing $p(h_{j\Omega}|d_\beta)$. \textbf{WE NEED TO DETERMINE THE EXTENT TO WHICH THERE IS MIXING BETWEEN POLARIZATION CHANNELS CAUSED BY THE SUMMATION OVER SKY POSITIONS.} If there is a better basis, we should work in that. What we want is to separate the sums, which makes this analysis much more straightforward.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliography{refs}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
